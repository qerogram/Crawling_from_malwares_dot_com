import requests, datetime, re, time, csv

class CrawlingMalwaresDotCom :    
    url = "https://www.malwares.com/ajax/search/tag"
    Request_Token = ""
    header = {
            "__RequestVerificationToken" : Request_Token,
            "page_num" : "1",
            "more_val" : "0",
            "up_cnt" : "0",
            "search_date" : "0",
            "tag_val" : "keywords",
            "tag_obt" : ""
        }

    def __init__(self, keywords, Tokens="") :
        self.header['tag_val'] = keywords
        self.Request_Token = Tokens
    
    def crawling(self) :
        page_num = 1
        f = open("hashlist.csv", "w")
        CSV_FILE = csv.writer(f)
        CSV_FILE.writerow(["SHA256"])

        while True :
            print(f"[+] Keyword = {self.header['tag_val']} / Page : {page_num} ")
            self.header['page_num'] = page_num
            self.header['search_date'] = str(datetime.datetime.now())[:-7]
            response = requests.post(self.url, data=self.header)
            data = response.text
            if len(data) < 50 :
                print(f"[+] Error ! Page : {page_num}")
                break

            for element in re.findall("<tr>.*?/tr>", data) :
                row = re.findall(r".+([A-Z0-9]{64}).+align_c'>([0-9]{1,3})", element)[0]
                if row[1] == '100' :
                    CSV_FILE.writerow([row[0]])
            page_num += 1
            time.sleep(5)
        f.close()

if __name__ == "__main__" :
    CMDC = CrawlingMalwaresDotCom(keywords="lazarus", Tokens="")
    CMDC.crawling()
